{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 11\n",
    "\n",
    "The purpose of this exercise is to develop as accurate as possible RNN (recurrent neural network) model that predicts electricity consumption in a property. \n",
    "\n",
    "Prediction:\n",
    "1. Predict the next hour electricity consumption\n",
    "2. Predict the next day (24h) electricity consumption \n",
    "\n",
    "The data set shows the hourly consumption of the property for the period from 1 January 2017 to 28 February 2022. The files are named as year-month.csv i.e. 2022-2.csv includes consumption from February 2022. Note: the timestamp 1.1.2017 00:00 is the electricity consumption from 1.1.2017 00:00 to 01:00. \n",
    "\n",
    "Zipped dataset file can be found from the Moodle: Electricity_consumption.zip\n",
    "\n",
    "Dataset splitting:\n",
    "1. Training dataset: 1.1.2017-30.9.2020\n",
    "2. Test dataset: 1.10.2020-30.9.2021\n",
    "3. \"Another test dataset\", which is used to when your RNN is ready: 1.10.2021-28.2.2022 \n",
    "\n",
    "\n",
    "Enrich data using open data from (Finnish meteorological Institute)[https://en.ilmatieteenlaitos.fi/]. \n",
    "- The weather station location is: Jyväskylä lentoasema, 137208, longitude: 62.39, latitude: 25.69\n",
    "- Enriched dataset have to contain AT LEAST the temperature, but you can use other information such as windy, humidity etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Power</th>\n",
       "      <th>Datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.39</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.08</td>\n",
       "      <td>2017-01-01 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.84</td>\n",
       "      <td>2017-01-01 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.66</td>\n",
       "      <td>2017-01-01 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.76</td>\n",
       "      <td>2017-01-01 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>3.61</td>\n",
       "      <td>2022-02-28 19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>2.42</td>\n",
       "      <td>2022-02-28 20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>5.97</td>\n",
       "      <td>2022-02-28 21:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>1.12</td>\n",
       "      <td>2022-02-28 22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>2.96</td>\n",
       "      <td>2022-02-28 23:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45240 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Power            Datetime\n",
       "0     1.39 2017-01-01 00:00:00\n",
       "1     3.08 2017-01-01 01:00:00\n",
       "2     0.84 2017-01-01 02:00:00\n",
       "3     1.66 2017-01-01 03:00:00\n",
       "4     0.76 2017-01-01 04:00:00\n",
       "..     ...                 ...\n",
       "667   3.61 2022-02-28 19:00:00\n",
       "668   2.42 2022-02-28 20:00:00\n",
       "669   5.97 2022-02-28 21:00:00\n",
       "670   1.12 2022-02-28 22:00:00\n",
       "671   2.96 2022-02-28 23:00:00\n",
       "\n",
       "[45240 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# files are ANSI-encoded\n",
    "# got code for reading from Suvi Tarkiainen, added skipfooter\n",
    "files = glob.glob('electricity_consumption/*.csv')\n",
    "df_consumption = pd.concat([pd.read_csv(fp,encoding='windows-1252',sep=';', decimal = ',', skipfooter = 1, engine='python').assign(Year=os.path.basename(fp).split('-')[0]) \n",
    "       for fp in files])\n",
    "\n",
    "# TO DO: Is this UTC+2 time? Haven't used datetime's tzinfo-attribute.\n",
    "\n",
    "# Create datetime-column and drop extra\n",
    "df_consumption[['Date', 'Time']] = df_consumption['Time'].str.split(' ', 1, expand = True)\n",
    "df_consumption['Datetime'] = df_consumption['Time'] + ' ' + df_consumption['Date'] + df_consumption['Year']   \n",
    "df_consumption['Datetime'] = pd.to_datetime(df_consumption['Datetime'], dayfirst = True)\n",
    "df_consumption.drop(['Time', 'Date', 'Year'], axis = 1, inplace = True)\n",
    "\n",
    "#df_consumption.loc[:,'Datetime'] = pd.to_datetime(df_consumption.loc[:, 'Datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "#df_consumption.sort_values(by=\"Datetime\", inplace = True)\n",
    "#df_consumption.set_index('Datetime', inplace = True)\n",
    "df_consumption\n",
    "\n",
    "## Checking datetime conversion\n",
    "# df_consumption.loc['2022-03-01 00:00:00'] # March 1st returns empty\n",
    "# df_consumption.loc['2022-01-03 00:00:00'] # January 3rd returns value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precipitation amount (mm)</th>\n",
       "      <th>Air temperature (degC)</th>\n",
       "      <th>Wind speed (m/s)</th>\n",
       "      <th>Datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2017-01-01 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2017-01-01 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2017-01-01 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2017-01-01 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45236</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2022-02-28 20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45237</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2022-02-28 21:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45238</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2022-02-28 22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45239</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2022-02-28 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45240</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2022-03-01 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45241 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Precipitation amount (mm)  Air temperature (degC)  Wind speed (m/s)  \\\n",
       "0                            0.0                     2.2               4.9   \n",
       "1                            0.0                     1.9               4.1   \n",
       "2                            0.0                     1.7               4.1   \n",
       "3                            0.0                     1.3               4.8   \n",
       "4                            0.0                     0.7               4.4   \n",
       "...                          ...                     ...               ...   \n",
       "45236                        0.0                    -1.1               2.0   \n",
       "45237                        0.0                    -0.9               2.3   \n",
       "45238                        0.0                    -1.6               2.1   \n",
       "45239                        0.0                    -2.2               1.9   \n",
       "45240                        0.0                    -1.8               2.9   \n",
       "\n",
       "                 Datetime  \n",
       "0     2017-01-01 00:00:00  \n",
       "1     2017-01-01 01:00:00  \n",
       "2     2017-01-01 02:00:00  \n",
       "3     2017-01-01 03:00:00  \n",
       "4     2017-01-01 04:00:00  \n",
       "...                   ...  \n",
       "45236 2022-02-28 20:00:00  \n",
       "45237 2022-02-28 21:00:00  \n",
       "45238 2022-02-28 22:00:00  \n",
       "45239 2022-02-28 23:00:00  \n",
       "45240 2022-03-01 00:00:00  \n",
       "\n",
       "[45241 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enrich data using open data from (Finnish meteorological Institute)[https://en.ilmatieteenlaitos.fi/].\n",
    "# The weather station location is: Jyväskylä lentoasema, 137208, longitude: 62.39, latitude: 25.69\n",
    "# Enriched dataset have to contain AT LEAST the temperature, but you can use other information such as windy, humidity etc.\n",
    "# I chose Precipitation amount, Air temperature, Wind speed\n",
    "\n",
    "df_weather = pd.read_csv('data/ex-11-weather-data-jkl-lentoasema.csv')\n",
    "\n",
    "df_weather['Datetime'] = df_weather['Year'].astype(str) + '.' + df_weather['m'].astype(str) + '.' + df_weather['d'].astype(str) + ' ' + df_weather['Time'] + ':00'\n",
    "df_weather['Datetime'] = pd.to_datetime(df_weather['Datetime'])\n",
    "\n",
    "# Data UTC-ajassa, joten oikeasti +2h, toisen datan osalta ei tietoa onko UTC vai UTC+2. \n",
    "# TO DO: Pitäisikö lisätä timedate-objectiin tzinfo (https://docs.python.org/3/library/datetime.html) tai jollain muulla tavalla mätsätä\n",
    "\n",
    "df_weather.drop(['Year', 'm', 'd', 'Time', 'Time zone' ], axis = 1, inplace = True)\n",
    "\n",
    "# df_weather.dtypes\n",
    "# df_weather.set_index('Datetime', inplace = True)\n",
    "# print(df_weather.loc['2022-03-01 00:00:00']) # March 1st returns value - mutta tätä ei tarvita\n",
    "# print(df_weather.loc['2022-01-03 00:00:00']) # January 3rd returns value\n",
    "\n",
    "df_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Power</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Precipitation amount (mm)</th>\n",
       "      <th>Air temperature (degC)</th>\n",
       "      <th>Wind speed (m/s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.39</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.08</td>\n",
       "      <td>2017-01-01 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.84</td>\n",
       "      <td>2017-01-01 02:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.66</td>\n",
       "      <td>2017-01-01 03:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.76</td>\n",
       "      <td>2017-01-01 04:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45235</th>\n",
       "      <td>3.61</td>\n",
       "      <td>2022-02-28 19:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45236</th>\n",
       "      <td>2.42</td>\n",
       "      <td>2022-02-28 20:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45237</th>\n",
       "      <td>5.97</td>\n",
       "      <td>2022-02-28 21:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45238</th>\n",
       "      <td>1.12</td>\n",
       "      <td>2022-02-28 22:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45239</th>\n",
       "      <td>2.96</td>\n",
       "      <td>2022-02-28 23:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45240 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Power            Datetime  Precipitation amount (mm)  \\\n",
       "0       1.39 2017-01-01 00:00:00                        0.0   \n",
       "1       3.08 2017-01-01 01:00:00                        0.0   \n",
       "2       0.84 2017-01-01 02:00:00                        0.0   \n",
       "3       1.66 2017-01-01 03:00:00                        0.0   \n",
       "4       0.76 2017-01-01 04:00:00                        0.0   \n",
       "...      ...                 ...                        ...   \n",
       "45235   3.61 2022-02-28 19:00:00                        0.0   \n",
       "45236   2.42 2022-02-28 20:00:00                        0.0   \n",
       "45237   5.97 2022-02-28 21:00:00                        0.0   \n",
       "45238   1.12 2022-02-28 22:00:00                        0.0   \n",
       "45239   2.96 2022-02-28 23:00:00                        0.0   \n",
       "\n",
       "       Air temperature (degC)  Wind speed (m/s)  \n",
       "0                         2.2               4.9  \n",
       "1                         1.9               4.1  \n",
       "2                         1.7               4.1  \n",
       "3                         1.3               4.8  \n",
       "4                         0.7               4.4  \n",
       "...                       ...               ...  \n",
       "45235                    -1.0               1.6  \n",
       "45236                    -1.1               2.0  \n",
       "45237                    -0.9               2.3  \n",
       "45238                    -1.6               2.1  \n",
       "45239                    -2.2               1.9  \n",
       "\n",
       "[45240 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_consumption_weather = pd.merge(df, df_weather, how='inner', left_on='Datetime', right_on='Datetime')\n",
    "df_consumption_weather = pd.merge(df_consumption, df_weather, how='inner', on='Datetime')\n",
    "\n",
    "df_consumption_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power                          0\n",
       "Datetime                       0\n",
       "Precipitation amount (mm)    233\n",
       "Air temperature (degC)       161\n",
       "Wind speed (m/s)             409\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_consumption_weather.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 45240 entries, 0 to 45239\n",
      "Data columns (total 5 columns):\n",
      " #   Column                     Non-Null Count  Dtype         \n",
      "---  ------                     --------------  -----         \n",
      " 0   Power                      45240 non-null  float64       \n",
      " 1   Datetime                   45240 non-null  datetime64[ns]\n",
      " 2   Precipitation amount (mm)  45007 non-null  float64       \n",
      " 3   Air temperature (degC)     45079 non-null  float64       \n",
      " 4   Wind speed (m/s)           44831 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(4)\n",
      "memory usage: 2.1 MB\n"
     ]
    }
   ],
   "source": [
    "df_consumption_weather.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consumption_weather.set_index('Datetime', inplace = True)\n",
    "\n",
    "# Seems like the longest period without some enriched data is 52h\n",
    "# for now I'll just interpolate it, but it is not the best way for this sort of data\n",
    "# TO DO if time: when filling, take into account time of day etc.\n",
    "df_consumption_weather.interpolate(method= 'time', limit_direction='both', limit = 26, inplace = True) \n",
    "\n",
    "# https://www.kaggle.com/code/juejuewang/handle-missing-values-in-time-series-for-beginners/report\n",
    "# https://machinelearningmastery.com/resample-interpolate-time-series-data-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 45240 entries, 2017-01-01 00:00:00 to 2022-02-28 23:00:00\n",
      "Data columns (total 4 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Power                      45240 non-null  float64\n",
      " 1   Precipitation amount (mm)  45240 non-null  float64\n",
      " 2   Air temperature (degC)     45240 non-null  float64\n",
      " 3   Wind speed (m/s)           45240 non-null  float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 1.7 MB\n"
     ]
    }
   ],
   "source": [
    "df_consumption_weather.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45240"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_consumption_weather.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.lineplot(y='Power', data=df_consumption_weather) #hue='Wind speed (m/s)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset splitting:\n",
    "\n",
    "# Training dataset: 1.1.2017-30.9.2020\n",
    "# Test dataset: 1.10.2020-30.9.2021\n",
    "# \"Another test dataset\", which is used to when your RNN is ready: 1.10.2021-28.2.2022\n",
    "\n",
    "df_train = df_consumption_weather.loc['2017-01-01 00:00:00':'2020-09-30 23:00:00']\n",
    "df_test = df_consumption_weather.loc['2020-10-01 00:00:00':'2021-09-30 23:00:00']\n",
    "df_test2 = df_consumption_weather.loc['2021-10-01 00:00:00':'2022-02-28 23:00:00'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35064, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32855, 4) ja 32856\n",
      "(8760, 4) ja 8760\n",
      "(3625, 4) ja 3624\n"
     ]
    }
   ],
   "source": [
    "print(f'{df_train.shape} ja {1369 * 24}')\n",
    "print(f'{df_test.shape} ja {365 * 24}')\n",
    "print(f'{df_test2.shape} ja {151 * 24}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving prepared data to csv-files to be used for rest of the training of Exercise 11 and Exercise 12\n",
    "\n",
    "df_train.to_csv('data/df_11_train.csv')\n",
    "df_test.to_csv('data/df_11_test.csv')\n",
    "df_test2.to_csv('data/df_11_test2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rest of the training is done on another workbook, because my local environment run into this issue \n",
    "https://github.com/tensorflow/models/issues/9706"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_to_features_and_target(data):\n",
    "    y = data[['Power']].copy()\n",
    "    X = data.drop(['Power'], axis = 1).copy()\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = split_to_features_and_target(df_train)\n",
    "X_test, y_test = split_to_features_and_target(df_test)\n",
    "X_test2, y_test2 = split_to_features_and_target(df_test2)\n",
    "\n",
    "# Scaling\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test2_scaled = scaler.transform(X_test2)\n",
    "\n",
    "scalero = MinMaxScaler()\n",
    "scalero.fit(y_train)\n",
    "y_train_scaled = scalero.transform(y_train)\n",
    "y_test_scaled = scalero.transform(y_test)\n",
    "y_test2_scaled = scalero.transform(y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.5264    , 0.32885906],\n",
       "       [0.        , 0.5216    , 0.27516779],\n",
       "       [0.        , 0.5184    , 0.27516779],\n",
       "       ...,\n",
       "       [0.        , 0.6624    , 0.0738255 ],\n",
       "       [0.        , 0.6528    , 0.04697987],\n",
       "       [0.        , 0.6528    , 0.06711409]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34991, 72, 3)\n",
      "(16727, 72, 3)\n",
      "(9359, 72, 3)\n",
      "(34991, 72, 1)\n",
      "(16727, 72, 1)\n",
      "(9359, 72, 1)\n"
     ]
    }
   ],
   "source": [
    "# Stepify Satu Sadulta! Muokattu hieman.\n",
    "\n",
    "def stepify(data):\n",
    "    lookback = 72\n",
    "    X=[]\n",
    "\n",
    "    for i in range(len(data) - lookback - 1):\n",
    "        t=[]\n",
    "        for j in range(0, lookback):\n",
    "            t.append(data[[(i + j)], :])\n",
    "        X.append(t)\n",
    "        \n",
    "    X = np.array(X)\n",
    "    X = X.reshape(X.shape[0], lookback, data.shape[1]) # data.shape[1] is used for getting no, features/targets\n",
    "    print(X.shape)\n",
    "    return X\n",
    "\n",
    "X_train_scaled_steps = stepify(X_train_scaled)\n",
    "X_test_scaled_steps = stepify(X_test_scaled)\n",
    "X_test2_scaled_steps = stepify(X_test2_scaled)\n",
    "\n",
    "y_train_scaled_steps = stepify(y_train_scaled)\n",
    "y_test_scaled_steps = stepify(y_test_scaled)\n",
    "y_test2_scaled_steps = stepify(y_test2_scaled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.         0.5264     0.32885906]\n",
      "  [0.         0.5216     0.27516779]\n",
      "  [0.         0.5184     0.27516779]\n",
      "  ...\n",
      "  [0.01360544 0.3008     0.37583893]\n",
      "  [0.         0.2944     0.3557047 ]\n",
      "  [0.         0.288      0.34899329]]\n",
      "\n",
      " [[0.         0.5216     0.27516779]\n",
      "  [0.         0.5184     0.27516779]\n",
      "  [0.         0.512      0.32214765]\n",
      "  ...\n",
      "  [0.         0.2944     0.3557047 ]\n",
      "  [0.         0.288      0.34899329]\n",
      "  [0.         0.2816     0.26845638]]\n",
      "\n",
      " [[0.         0.5184     0.27516779]\n",
      "  [0.         0.512      0.32214765]\n",
      "  [0.         0.5024     0.29530201]\n",
      "  ...\n",
      "  [0.         0.288      0.34899329]\n",
      "  [0.         0.2816     0.26845638]\n",
      "  [0.         0.2688     0.2885906 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.         0.6368     0.03355705]\n",
      "  [0.         0.6128     0.04026846]\n",
      "  [0.         0.6112     0.05369128]\n",
      "  ...\n",
      "  [0.         0.6704     0.0738255 ]\n",
      "  [0.         0.6704     0.0738255 ]\n",
      "  [0.         0.6672     0.10067114]]\n",
      "\n",
      " [[0.         0.6128     0.04026846]\n",
      "  [0.         0.6112     0.05369128]\n",
      "  [0.         0.6064     0.04026846]\n",
      "  ...\n",
      "  [0.         0.6704     0.0738255 ]\n",
      "  [0.         0.6672     0.10067114]\n",
      "  [0.         0.6656     0.06711409]]\n",
      "\n",
      " [[0.         0.6112     0.05369128]\n",
      "  [0.         0.6064     0.04026846]\n",
      "  [0.         0.6        0.        ]\n",
      "  ...\n",
      "  [0.         0.6672     0.10067114]\n",
      "  [0.         0.6656     0.06711409]\n",
      "  [0.         0.6624     0.0738255 ]]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_scaled_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Cannot convert a symbolic Tensor (simple_rnn_1/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\RIIKKA~1.NAU\\AppData\\Local\\Temp/ipykernel_8552/2077523429.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0minput_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m72\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mrnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSimpleRNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m72\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m rnn_model = tf.keras.Model(inputs = input_layer,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 663\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    664\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m     \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    923\u001b[0m     \u001b[1;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    924\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 925\u001b[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[0;32m    926\u001b[0m                                                 input_list)\n\u001b[0;32m    927\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1115\u001b[0m           \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1117\u001b[1;33m               \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[0;32m   1570\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1571\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_reset_cell_dropout_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1572\u001b[1;33m     return super(SimpleRNN, self).call(\n\u001b[0m\u001b[0;32m   1573\u001b[0m         inputs, mask=mask, training=training, initial_state=initial_state)\n\u001b[0;32m   1574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask, training, initial_state, constants)\u001b[0m\n\u001b[0;32m    732\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_args_if_ragged\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_ragged_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 734\u001b[1;33m     inputs, initial_state, constants = self._process_inputs(\n\u001b[0m\u001b[0;32m    735\u001b[0m         inputs, initial_state, constants)\n\u001b[0;32m    736\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(self, inputs, initial_state, constants)\u001b[0m\n\u001b[0;32m    860\u001b[0m         \u001b[0minitial_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m       \u001b[0minitial_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_initial_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mget_initial_state\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    643\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mget_initial_state_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m       init_state = get_initial_state_fn(\n\u001b[0m\u001b[0;32m    646\u001b[0m           inputs=None, batch_size=batch_size, dtype=dtype)\n\u001b[0;32m    647\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mget_initial_state\u001b[1;34m(self, inputs, batch_size, dtype)\u001b[0m\n\u001b[0;32m   1383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_initial_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1385\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_generate_zero_filled_state_for_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1387\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m_generate_zero_filled_state_for_cell\u001b[1;34m(cell, inputs, batch_size, dtype)\u001b[0m\n\u001b[0;32m   2966\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2967\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2968\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0m_generate_zero_filled_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2969\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2970\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m_generate_zero_filled_state\u001b[1;34m(batch_size_tensor, state_size, dtype)\u001b[0m\n\u001b[0;32m   2984\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreate_zeros\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2985\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2986\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_zeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2988\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mcreate_zeros\u001b[1;34m(unnested_state_size)\u001b[0m\n\u001b[0;32m   2979\u001b[0m     \u001b[0mflat_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munnested_state_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2980\u001b[0m     \u001b[0minit_state_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_size_tensor\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mflat_dims\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2981\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_state_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2982\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2983\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2745\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2746\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2747\u001b[1;33m     \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2748\u001b[0m     \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_zeros_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2749\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mzeros\u001b[1;34m(shape, dtype, name)\u001b[0m\n\u001b[0;32m   2792\u001b[0m           \u001b[1;31m# Create a constant if it won't be very big. Otherwise create a fill\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2793\u001b[0m           \u001b[1;31m# op to prevent serialized GraphDefs from becoming too large.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2794\u001b[1;33m           \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_constant_if_small\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzero\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2795\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2796\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m_constant_if_small\u001b[1;34m(value, shape, dtype, name)\u001b[0m\n\u001b[0;32m   2730\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_if_small\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2731\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2732\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2733\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2734\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mprod\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   3028\u001b[0m     \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3029\u001b[0m     \"\"\"\n\u001b[1;32m-> 3030\u001b[1;33m     return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n\u001b[0m\u001b[0;32m   3031\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0;32m   3032\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    843\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 845\u001b[1;33m     raise NotImplementedError(\n\u001b[0m\u001b[0;32m    846\u001b[0m         \u001b[1;34m\"Cannot convert a symbolic Tensor ({}) to a numpy array.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m         \u001b[1;34m\" This error may indicate that you're trying to pass a Tensor to\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Cannot convert a symbolic Tensor (simple_rnn_1/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "# 1 hour prediction\n",
    "\n",
    "input_layer = tf.keras.Input(shape=(72,3))\n",
    "rnn = tf.keras.layers.SimpleRNN(72)(input_layer)\n",
    "output = tf.keras.layers.Dense(1)(rnn)\n",
    "rnn_model = tf.keras.Model(inputs = input_layer,\n",
    "                           outputs = output)\n",
    "\n",
    "rnn_model.compile(optimizer='adam',\n",
    "                   loss='mse',\n",
    "                   metrics=['mean_squared_error'])\n",
    "\n",
    "rnn_model.fit(X_train_scaled_steps, y_train_scaled_steps, epochs=10, verbose=1)\n",
    "test_results = rnn_model.evaluate(X_test_scaled_steps, y_test_scaled_steps, verbose=0)\n",
    "predictions = rnn_model.predict(X_test_scaled_steps)\n",
    "print(f\"Test loss {test_results[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Please see Exercise11-training-model-in-colab.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# own notes, please ignore\n",
    "\n",
    "## split when column\n",
    "# split_date_train = datetime(2020, 9, 30) + timedelta(days=1)\n",
    "# split_date_test = datetime(2021, 9 ,30) + timedelta(days=1)\n",
    "\n",
    "# df_training = df_consumption_weather.loc[df_consumption_weather['Datetime'] <= split_date_train ]\n",
    "# df_test = df_consumption_weather.loc[(df_consumption_weather['Datetime'] > split_date_train) & (df_consumption_weather['Datetime'] <= split_date_test)]\n",
    "# df_test2 = df_consumption_weather.loc[df_consumption_weather['Datetime'] > split_date_test]\n",
    "\n",
    "\n",
    "# --\n",
    "\n",
    "# split_date_train = datetime(2020, 9, 30) + timedelta(hours=23)\n",
    "# split_date_test = datetime(2021, 9, 30) + timedelta(hours=23)\n",
    "# df_train = df_consumption_weather[:split_date_train]\n",
    "# df_test = df_consumption_weather[split_date_train + timedelta(hours=1):split_date_test]\n",
    "# df_test2 = df_consumption_weather[split_date_test + timedelta(hours=1):]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
